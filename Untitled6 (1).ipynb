{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8d3BHiX29PD"
      },
      "source": [
        "# Project Descreption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB7qY8bs26BD"
      },
      "source": [
        "The Objective of this project is :\n",
        "\n",
        "1.   Use the OpenFoodFact   that shows  characteristics of certain product groups, similarities between products and product groups, to provide a global view of the dataset, and exhibit salient features that are of interest for an analyst or stakeholder in this sector.\n",
        "\n",
        "2.   Use some machine learning algorithms to : \n",
        "\n",
        "        *   predict the **nutriscore_grade** of a product given nutritional values and possibly other fields (as few as possible)\n",
        "        *   predict the **nova_group** of a product given nutritional values and possibly other fields (as few as possible),\n",
        "        *   predict the **pnns_groups_1** of a product given nutritional values and possibly other fields (as few as possible),\n",
        "        *   predict the **pnns_groups_2** of a product given nutritional values and possibly other fields (as few as possible),\n",
        "        *   predict the **categories** (either atomic categories or lists of categories) of a product given nutritional values and possibly other fields (as few as possible),\n",
        "        *   predict one or more **nutritional values** (ex: sugars_100g) given nutritional values and possibly other fields (as few as possible)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIzZtUkU7hHC"
      },
      "source": [
        "# Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfs3MJGW0Nef"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn')\n",
        "from scipy.stats import norm, skew\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import  StandardScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from scipy.stats import skew\n",
        "from scipy.special import boxcox1p\n",
        "from scipy.stats import boxcox_normmax\n",
        "import statsmodels.api as sm\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
        "import lightgbm as lgb\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3sSjVaZ8ZJ9"
      },
      "source": [
        "# Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJoQnJ0X1PnT"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nygdy2reyHCO"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/off_complete.csv', sep = '\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssQyBMqNyKLs"
      },
      "source": [
        "data.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OFzKIF8yUSt"
      },
      "source": [
        "# Data Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VewcQhYPLiV_"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (30, 20)\n",
        "sns.heatmap(data.corr(), annot = True)\n",
        "plt.title('Histogram of the Dataset', fontsize = 30)\n",
        "plt.xticks(size = 25)\n",
        "plt.yticks(size = 25)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYDO7HFeMN63"
      },
      "source": [
        "**Note :**\n",
        "From the heatmap, we can see that **Nutriscore_score** and **Nutriscore_score_fr** are totaly correlated, and **Sodium** and **Salt** too, so we can delete them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka2PXzVUM6h7"
      },
      "source": [
        "data.drop(['salt_100g'], 1, inplace=True)\n",
        "data.drop(['nutrition-score-fr_100g'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hK6_hNU5Xc8"
      },
      "source": [
        "**Comparison the nutriscore grade for every code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zT5uk4gyX4G"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "sns.countplot(data['nutriscore_grade'], palette = 'pink')\n",
        "plt.title('Most Existing Nutriscore Grade ', fontsize = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pp_ymtF5w6Q"
      },
      "source": [
        "**comparison of nova_group for every code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfAw9rbR5sZ-"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (10, 5)\n",
        "sns.countplot(data['nova_group'])\n",
        "plt.title('Most Existing nova_group ', fontsize = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J215dZrY6RuL"
      },
      "source": [
        "different pnns_groups_1 acquired by the the products"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Ks4FG95seG"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (40, 25)\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "ax = sns.countplot(data['pnns_groups_1'], palette = 'bone')\n",
        "ax.set_xlabel(xlabel = 'Different pnns_groups_1', fontsize = 40)\n",
        "ax.set_ylabel(ylabel = 'Count of Products', fontsize = 40)\n",
        "ax.set_title(label = 'Comparison of pnns_groups_1 and products', fontsize = 40)\n",
        "plt.xticks(size = 25)\n",
        "plt.yticks(size = 30)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s456aLF66iAB"
      },
      "source": [
        "**Comparing the product's nutriscore_score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCnOoWcY6iRD"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (25, 15)\n",
        "sns.distplot(data['nutriscore_score'], color = 'blue')\n",
        "plt.xlabel('nutriscore_score Range for Products', fontsize = 16)\n",
        "plt.ylabel('Count of the Products', fontsize = 16)\n",
        "plt.title('Distribution of nutriscore_score of Products', fontsize = 20)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ornX4GoCPlR"
      },
      "source": [
        " show Different fat_100g of the products"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R9DyAPL5sYR"
      },
      "source": [
        "sns.distplot(data['fat_100g'], color = 'pink')\n",
        "plt.title('Different fat_100g of the products')\n",
        "plt.xlabel('fat_100g associated with the Products')\n",
        "plt.ylabel('count of Products')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l_fhOXkCO0g"
      },
      "source": [
        "`show Different countries tags that these products come from`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZWj4KZzCaMo"
      },
      "source": [
        "data['countries_tags'].value_counts().head(20).plot.bar(color = 'orange', figsize = (20, 7))\n",
        "plt.title('Different countries tags that these products come from', fontsize = 30, fontweight = 20)\n",
        "plt.xlabel('Name of The Country')\n",
        "plt.ylabel('count')\n",
        "plt.xticks(size = 25)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp6fH-BfC0gg"
      },
      "source": [
        "**show Different brands of the products**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuveYMs-CaWt"
      },
      "source": [
        "data['brands'].value_counts().head(20).plot.bar(color = 'orange', figsize = (15, 7))\n",
        "plt.title('Different brands of the products', fontsize = 30, fontweight = 20)\n",
        "plt.xlabel('Name of The Brand')\n",
        "plt.ylabel('count')\n",
        "plt.xticks(size = 25)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrlinM9bC6_i"
      },
      "source": [
        "best product per each nutriscore_grade with their , pnns_groups_2, pnns_groups_1 and code  based on their  energy-kcal_100g\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqvrDeKHCabg"
      },
      "source": [
        "data.iloc[data.groupby(data['nutriscore_grade'])['energy-kcal_100g'].idxmax()][['nutriscore_grade','product_name','nova_group', 'pnns_groups_1',\n",
        "                                                                    'pnns_groups_2','energy-kcal_100g']].style.background_gradient('Reds')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac-NA4AXDUW9"
      },
      "source": [
        "best product per each nutriscore_grade with their , pnns_groups_2, pnns_groups_1 and code  based on their  proteins_100g\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R75Xx1xjCaf5"
      },
      "source": [
        "data.iloc[data.groupby(data['nutriscore_grade'])['proteins_100g'].idxmax()][['nutriscore_grade','product_name','nova_group', 'pnns_groups_1',\n",
        "                                                                    'pnns_groups_2','proteins_100g']].style.background_gradient('Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZUrNf5eEenw"
      },
      "source": [
        "**best product per each nutriscore_grade with their , pnns_groups_2, pnns_groups_1 and code  based on their  energy-kcal_100g**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iic_LCqCCaae"
      },
      "source": [
        "data.iloc[data.groupby(data['nutriscore_grade'])['carbohydrates_100g'].idxmax()][['nutriscore_grade','product_name','nova_group', 'pnns_groups_1',\n",
        "                                                                    'pnns_groups_2','carbohydrates_100g']].style.background_gradient('Reds')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MdVUc7UE7xD"
      },
      "source": [
        "**picking up the countries_tags with highest number of products**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IleKqqEEE789"
      },
      "source": [
        "data['countries_tags'].value_counts().head(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZSE7wrFFdDK"
      },
      "source": [
        "**the most  countries_tags's products and their nutriscore_score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBHCIu8NE8E1"
      },
      "source": [
        "some_countries = ('en:france', 'en:united-states', 'en:spain', 'en:belgium', 'en:united-kingdom', 'en:germany',\n",
        "                  'en:canada', 'en:france,en:germany')\n",
        "data_countries = data.loc[data['countries_tags'].isin(some_countries) & data['nutriscore_score']]\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (15, 7)\n",
        "ax = sns.violinplot(x = data_countries['countries_tags'], y = data_countries['nutriscore_score'], palette = 'Reds')\n",
        "ax.set_xlabel(xlabel = 'countries_tags', fontsize = 9)\n",
        "ax.set_ylabel(ylabel = 'nutriscore_scores', fontsize = 9)\n",
        "ax.set_title(label = 'Distribution of nutriscore_score of products from different countries_tags', fontsize = 20)\n",
        "plt.xticks(size = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK1hGcZ4Gp8o"
      },
      "source": [
        "**Every countries_tags's Product and their energy-kcal_100g**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzbqQw5JCaVL"
      },
      "source": [
        "some_countries = ('en:france', 'en:united-states', 'en:spain', 'en:belgium', 'en:united-kingdom', 'en:germany',\n",
        "                  'en:canada', 'en:france,en:germany')\n",
        "data_countries = data.loc[data['countries_tags'].isin(some_countries) & data['energy-kcal_100g']]\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (15, 7)\n",
        "ax = sns.barplot(x = data_countries['countries_tags'], y = data_countries['energy-kcal_100g'],palette = 'Purples')\n",
        "ax.set_xlabel(xlabel = 'countries_tags', fontsize = 9)\n",
        "ax.set_ylabel(ylabel = 'energy-kcal_100g', fontsize = 9)\n",
        "ax.set_title(label = 'Distribution of energy-kcal_100g of products from different countries_tags', fontsize = 20)\n",
        "plt.xticks(size = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFtydC7uHF-N"
      },
      "source": [
        "\n",
        "**the the most used and popular product**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhEmUo9vGpcH"
      },
      "source": [
        "data['product_name'].value_counts().head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKvoxbtSGpho"
      },
      "source": [
        "some_products = ('Pâte à sucre', 'The Madelaine Chocolate Company, Solid Milk Chocolate', 'Glaçage fondant'\n",
        "                 , 'Colorant alimentaire', 'Pain aux 2 lins', 'Miel',\n",
        "             'The Madelaine Chocolate Company, Solid Dark Chocolate', 'Crème dessert chocolat', 'Vitória crackers')\n",
        "\n",
        "data_products = data.loc[data['product_name'].isin(some_products) & data['sugars_100g']]\n",
        "\n",
        "ax = sns.boxplot(x = data_products['product_name'], y = data_products['sugars_100g'], palette = 'inferno')\n",
        "ax.set_xlabel(xlabel = 'Some Popular product_name', fontsize = 9)\n",
        "ax.set_ylabel(ylabel = ' sugars_100g', fontsize = 9)\n",
        "ax.set_title(label = 'Distribution of sugars_100g  in Different popular product_name', fontsize = 20)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.xticks(size = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rAI0_bKHfuJ"
      },
      "source": [
        "**Distribution of nutriscore_score in some Popular products**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBqajM_oGpai"
      },
      "source": [
        "some_products = ('Pâte à sucre', 'The Madelaine Chocolate Company, Solid Milk Chocolate', 'Glaçage fondant', 'Colorant alimentaire',\n",
        "                 'Pain aux 2 lins', 'Miel','The Madelaine Chocolate Company, Solid Dark Chocolate', 'Crème dessert chocolat', 'Vitória crackers')\n",
        "\n",
        "data_products = data.loc[data['product_name'].isin(some_products) & data['nutriscore_score']]\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (16, 8)\n",
        "ax = sns.violinplot(x = 'product_name', y = 'nutriscore_score', data = data_products, palette = 'bright')\n",
        "ax.set_xlabel(xlabel = 'Names of some popular products', fontsize = 10)\n",
        "ax.set_ylabel(ylabel = 'Distribution of nutriscore_score', fontsize = 10)\n",
        "ax.set_title(label = 'Disstribution of nutriscore_score  in some Popular product_name', fontsize = 20)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8VB2k0KH_pU"
      },
      "source": [
        " finding 15 poorest products from  Calcium\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lu68H3YH3et"
      },
      "source": [
        "data.sort_values('calcium_100g', ascending = True)[['product_name','nutriscore_grade', 'code', 'nutriscore_score'\n",
        ",'countries_tags', 'calcium_100g']].head(15).style.background_gradient('viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9hm7arAIMPd"
      },
      "source": [
        "finding 15 richest products from  Calcium"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0w654l3H3kF"
      },
      "source": [
        "\n",
        "data.sort_values('calcium_100g', ascending = False)[['product_name','nutriscore_grade', 'code', 'nutriscore_score',\n",
        "                                                   'countries_tags', 'calcium_100g']].head(15).style.background_gradient('viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHpItwrwIXvQ"
      },
      "source": [
        "finding 15 poorest products from  Energie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE6AgnRkH3ik"
      },
      "source": [
        "data.sort_values('energy-kcal_100g', ascending = True)[['product_name', 'nutriscore_grade','code', 'nutriscore_score',\n",
        "                                                      'countries_tags', 'energy-kcal_100g']].head(15).style.background_gradient('viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzR9CPXoItky"
      },
      "source": [
        "**Finding 15 richest products from  Energie**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mTfjtTKH3dF"
      },
      "source": [
        "data.sort_values('energy-kcal_100g', ascending = False)[['product_name', 'nutriscore_grade','code', \n",
        "                                                       'nutriscore_score','countries_tags', 'energy-kcal_100g']].head(15).style.background_gradient('viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PTkH_J5Jind"
      },
      "source": [
        "def productdata(x):\n",
        "    return data.loc[x,:]\n",
        "\n",
        "x = productdata(233)  \n",
        "pd.set_option('display.max_rows', 200)\n",
        "x = pd.DataFrame(x)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vdBaJTN8fRM"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFpcCw04739T"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl8C-Sq28qDd"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjoUW3UZ9s_k"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWClt78lIisy"
      },
      "source": [
        "**Note**\n",
        "\n",
        "While the code of products refers to manufacturer-specific coding with tariff indication, The country or the company markets the product, The manufacturer, the Article code and a control key, so we can drop the  product code , because we already have the country that markets the product."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V8WxKwb-n4k"
      },
      "source": [
        "data.drop(['code'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua4oj2IhKwc_"
      },
      "source": [
        "data['url'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIxy0SMIK7oj"
      },
      "source": [
        "**Note :**\n",
        "\n",
        "We see that in every url of the products, it contains the product name and the brand, so we can drop this feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAtJXivsKwbz"
      },
      "source": [
        "data.drop(['url'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY-o4eXSvagS"
      },
      "source": [
        "I will Try to find the pourcentage of the null values in every features, and drop the features with more than 70% of null values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7B8G43GOBQB"
      },
      "source": [
        "for i in data.columns:\n",
        "    h = (data[i].isnull().sum()/len(data['product_name']))*100\n",
        "    print('The pourcentage of the null values of '+i+' is : ', h, '%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHZMyhhKvxt7"
      },
      "source": [
        "data.drop(['trans-fat_100g'], 1, inplace=True)\n",
        "data.drop(['cholesterol_100g'], 1, inplace=True)\n",
        "data.drop(['vitamin-a_100g'], 1, inplace=True)\n",
        "data.drop(['vitamin-c_100g'], 1, inplace=True)\n",
        "data.drop(['calcium_100g'], 1, inplace=True)\n",
        "data.drop(['iron_100g'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaG-UebI3JSr"
      },
      "source": [
        "I will Pick up the countries_tags with highest number of products \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MeQRroKHauj"
      },
      "source": [
        "data['countries_tags'].value_counts().head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xV3okyBLPXg"
      },
      "source": [
        "data['countries_tags']=data['countries_tags'].fillna('Unknown')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pwIDV8TKoiU"
      },
      "source": [
        "countries_tags_values = data['countries_tags'].values\n",
        "most_countries = ('en:france' , 'en:germany',  'en:spain' , 'en:mexico', 'en:united-kingdom' ,'en:poland', 'en:united-states', 'en:belgium','en:switzerland', 'en:thailand', 'en:sweden')\n",
        "countrie= {'en:france' : [], 'en:germany': [],  'en:spain': [] , 'en:mexico': [], 'en:united-kingdom': [], 'en:poland': [], 'en:united-states': [], 'en:belgium': [],'en:switzerland': [],\n",
        "           'en:thailand': [], 'en:sweden': []} \n",
        "for i in countries_tags_values : \n",
        "   for j in most_countries:\n",
        "       if j in str(i):\n",
        "         countrie[j].append(1)\n",
        "       else : \n",
        "          countrie[j].append(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1_kQisd5F9I"
      },
      "source": [
        "for i in most_countries:\n",
        "  data[i] = pd.DataFrame(countrie[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wZ9RPDKRLz2"
      },
      "source": [
        "data.drop(['countries_tags'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr4_sYzzaBzl"
      },
      "source": [
        "I will work on the Product Name Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngFT112cXB_U"
      },
      "source": [
        "product_names_list = data['product_name'].values\n",
        "list_products = []\n",
        "for i in product_names_list:\n",
        "  i = i.replace('Le', '')\n",
        "  i = i.replace('La', '')\n",
        "  i = i.replace('s', '')\n",
        "  first_word = i.split()[0]\n",
        "  list_products.append(first_word)\n",
        "data['product_name'] = pd.DataFrame(list_products)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMzZeWFvXB9J"
      },
      "source": [
        "data['product_name'].value_counts().head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg8X-36TZHDf"
      },
      "source": [
        "product_name__values = data['product_name'].values\n",
        "most_products = ('Sauce' , 'Yaourt',  'en:spain' , 'Petit', 'Crème' ,'Chocolat', 'Jambon', 'Confiture','Mini', 'Pain', 'Filet')\n",
        "products= {'Sauce':[] , 'Yaourt':[],  'en:spain':[] , 'Petit':[], 'Crème':[] ,'Chocolat':[], 'Jambon':[], 'Confiture':[],'Mini':[], 'Pain':[], 'Filet':[]} \n",
        "for i in product_name__values : \n",
        "   for j in most_products:\n",
        "       if j in str(i):\n",
        "         products[j].append(1)\n",
        "       else : \n",
        "          products[j].append(0)\n",
        "for i in most_products:\n",
        "  data[i] = pd.DataFrame(products[i])\n",
        "data.drop(['product_name'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAERKUZfdD0_"
      },
      "source": [
        "data.drop(['brands'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxI2o77SdP32"
      },
      "source": [
        "categories_list = data['categories'].values\n",
        "list_categories = []\n",
        "for i in categories_list:\n",
        "  first_word = i.split()[0]\n",
        "  first_word = first_word.replace(',', '')\n",
        "  list_categories.append(first_word)\n",
        "data['categories'] = pd.DataFrame(list_categories)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_MLVY74dv-E"
      },
      "source": [
        "data['categories'].value_counts().head(11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGzkq-5Rd-Uy"
      },
      "source": [
        "categories__values = data['categories'].values\n",
        "most_categories = ('Aliments' , 'Snacks',  'Produits' , 'Viandes', 'Boissons' ,'Pflanzliche', 'Alimentos', 'Plats','Epicerie', 'Plant-based', 'Desserts')\n",
        "categories= {'Aliments':[] , 'Snacks':[],  'Produits':[] , 'Viandes':[], 'Boissons':[] ,'Pflanzliche':[], 'Alimentos':[], 'Plats':[],'Epicerie':[], 'Plant-based':[], 'Desserts':[]} \n",
        "for i in categories__values : \n",
        "   for j in most_categories:\n",
        "       if j in str(i):\n",
        "         categories[j].append(1)\n",
        "       else : \n",
        "          categories[j].append(0)\n",
        "for i in most_categories:\n",
        "  data[i] = pd.DataFrame(categories[i])\n",
        "data.drop(['categories'], 1, inplace=True)\n",
        "data['Aliments'] = data['Aliments']+ data['Alimentos']\n",
        "aliments_values = data['Aliments'].values\n",
        "for i in range(len(aliments_values)):\n",
        "  if aliments_values[i]==2:\n",
        "        aliments_values[i] = 1\n",
        "data['Aliments'] = pd.DataFrame(aliments_values)\n",
        "data.drop(['Alimentos'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEm8lfVvdP2y"
      },
      "source": [
        "data.drop(['additives_tags','states'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djyt0LCDRVji"
      },
      "source": [
        "data['nutriscore_grade'].fillna('None', inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnGQncneRTrl"
      },
      "source": [
        "df =pd.get_dummies(data['nutriscore_grade'], drop_first=True)\n",
        "for i in df.columns : \n",
        "         data['nutriscore_grade_'+i] = df[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oft5O3asKqPD"
      },
      "source": [
        "def function_escalier(x):\n",
        "  if x >=0:\n",
        "      return(int(x+5))\n",
        "  else:\n",
        "    return int(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn2v_vvtkMez"
      },
      "source": [
        "data['nutriscore_score'] = data['nutriscore_score'].astype(float)\n",
        "data_grouped = data.groupby('pnns_groups_2')['nutriscore_score'].mean()\n",
        "grades = list(data['pnns_groups_2'].unique())\n",
        "for grade in grades:\n",
        "  p = data['pnns_groups_2'] == grade\n",
        "  data.loc[p, 'nutriscore_score'] = data.loc[p, 'nutriscore_score'].fillna(function_escalier(data_grouped[grade]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LKo-hIC4S-b"
      },
      "source": [
        "df =pd.get_dummies(data['nova_group'])\n",
        "for i in df.columns[:-1] : \n",
        "         data['nova_group'+str(i)] = df[i]\n",
        "data.drop(['nova_group'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nT2JLky-Ds0"
      },
      "source": [
        "data.drop(['nutriscore_grade'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SktuL5wgWBf-"
      },
      "source": [
        "dh = data.groupby(['pnns_groups_1'])['pnns_groups_2'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEMP5GvKZJDm"
      },
      "source": [
        "dh = list(dict(dh))\n",
        "dh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWZSeiKYbGjn"
      },
      "source": [
        "data['pnns_groups_1'].fillna('To Replace', inplace = True)\n",
        "d = data[data['pnns_groups_1'] =='To Replace']['pnns_groups_2']\n",
        "d.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIgvOHpgthyj"
      },
      "source": [
        "new_data = data[['pnns_groups_1','pnns_groups_2']].values\n",
        "a_list1 = []\n",
        "a_list2 = []\n",
        "for i in range(len(new_data)):\n",
        "     if new_data[i][1]=='Alcoholic beverages':\n",
        "        new_data[i][0] ='Beverages'\n",
        "     if new_data[i][1]=='Pizza pies and quiches':\n",
        "        new_data[i][0] ='Composite foods'\n",
        "df= pd.DataFrame(new_data, columns = ['pnns_groups_1','pnns_groups_2'])\n",
        "data['pnns_groups_1'] = df['pnns_groups_1'] \n",
        "data['pnns_groups_2'] = df['pnns_groups_2'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNZly8eNpRP2"
      },
      "source": [
        "lists= ['energy-kcal_100g','fat_100g', 'saturated-fat_100g','carbohydrates_100g','sugars_100g','fiber_100g','proteins_100g','sodium_100g']\n",
        "for feature in lists:\n",
        "    data[feature] = data[feature].astype(float)\n",
        "    data_grouped = data.groupby('pnns_groups_2')[feature].mean()\n",
        "    list_feature = list(data['pnns_groups_2'].unique())\n",
        "    for value_f in list_feature:\n",
        "         p = data['pnns_groups_2'] == value_f\n",
        "         data.loc[p, feature] = data.loc[p, feature].fillna(data_grouped[value_f])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7njCzbItxueU"
      },
      "source": [
        "data['fat_100g'] = data['fat_100g'].astype(float)\n",
        "data_grouped = data.groupby('pnns_groups_2')['fat_100g'].mean()\n",
        "grades = list(data['pnns_groups_2'].unique())\n",
        "for grade in grades:\n",
        "  p = data['pnns_groups_2'] == grade\n",
        "  data.loc[p, 'fat_100g'] = data.loc[p, 'fat_100g'].fillna(function_escalier(data_grouped[grade]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mu3wCltb5Jm"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvrwM7Xzb5D8"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syqGOcGbtDEq"
      },
      "source": [
        "data['pnns_groups_2'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zhpv6WKwWRu"
      },
      "source": [
        "df =pd.get_dummies(data[['pnns_groups_2']], drop_first=True)\n",
        "for i in df.columns : \n",
        "         data[i] = df[i]\n",
        "data.drop(['pnns_groups_2'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCyUrxNNwWWh"
      },
      "source": [
        "df =pd.get_dummies(data[['pnns_groups_1']], drop_first=True)\n",
        "for i in df.columns : \n",
        "         data[i] = df[i]\n",
        "data.drop(['pnns_groups_1'], 1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcKum8QIwWVO"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvUzhBNonhWp"
      },
      "source": [
        "data['nutriscore_score'] = data['nutriscore_score'].astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRgqM_bt0RBp"
      },
      "source": [
        "**Some Statistics : Skewness**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpVsh0rR0QFS"
      },
      "source": [
        "features = data\n",
        "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "numerics2 = []\n",
        "for i in features.columns:\n",
        "    if features[i].dtype in numeric_dtypes: \n",
        "        numerics2.append(i)\n",
        "\n",
        "skew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
        "skews = pd.DataFrame({'skew':skew_features})\n",
        "skews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj7KVqqK0QT2"
      },
      "source": [
        "**Handling The  Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEyIMYLZ2vaC"
      },
      "source": [
        "tr = data\n",
        "for y in tr.columns :\n",
        "  factor = 4\n",
        "  upper_lim = data[y].mean () + data[y].std () * factor\n",
        "  lower_lim = data[y].mean () - data[y].std () * factor\n",
        "  tr = data[(data[y] < upper_lim) & (data[y] > lower_lim)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os6UQSXFKM6G"
      },
      "source": [
        "\n",
        "\n",
        "# Prediction of the nutriscore_grade "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH-0jbL33qpI"
      },
      "source": [
        "X = data.drop(['nutriscore_score'], 1)\n",
        "y = data['nutriscore_score']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noc-Qhi43epv"
      },
      "source": [
        "overfit = []\n",
        "for i in X.columns:\n",
        "    counts = X[i].value_counts()\n",
        "    zeros = counts.iloc[0]\n",
        "    if zeros / len(X) * 100 >99.94:\n",
        "        overfit.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-1ATJSQ44WA"
      },
      "source": [
        "overfit = list(overfit)\n",
        "overfit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn5xuoQh5MEu"
      },
      "source": [
        "Let's drop these overfits from 'X' .  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtI00pJa5YHE"
      },
      "source": [
        "X.drop(overfit,axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF-IO5EZnUZW"
      },
      "source": [
        "Spliting the datasets into the training set and the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k837xwjD5lsh"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNBYoxaAnbPl"
      },
      "source": [
        "Scaling the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfQb5Fndkr5E"
      },
      "source": [
        "sc = StandardScaler()\n",
        "X_train[:, 1:8] = sc.fit_transform(X_train[:, 1:8])\n",
        "X_test[:, 1:8] = sc.transform(X_test[:, 1:8])\n",
        "sc2 = StandardScaler()\n",
        "y_train = sc2.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test= sc2.transform(y_test.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEgdV9hKAdMW"
      },
      "source": [
        "Now that the data is ready, we will try to apply the **Regularization** to the data set using to methods : \n",
        "\n",
        "*   The Ridge method.\n",
        "*   The Lasso method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7yB-7fW4P8D"
      },
      "source": [
        "def rmse_cv(model):\n",
        "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 10))\n",
        "    return(rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBO7IJTPDuH3"
      },
      "source": [
        "model_ridge = Ridge()\n",
        "alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\n",
        "cv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() for alpha in alphas]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfgTKoj0DuNs"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (30, 20)\n",
        "cv_ridge = pd.Series(cv_ridge, index = alphas)\n",
        "cv_ridge.plot(title = \"Validation - Just Do It\")\n",
        "plt.xlabel(\"alpha\")\n",
        "plt.xticks(size = 20)\n",
        "plt.ylabel(\"rmse\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KCp2vd4IK63"
      },
      "source": [
        "cv_ridge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyUMlkNAEYHu"
      },
      "source": [
        "**Note :** we can see that the value of alpha that gives the best values is between 0 and 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34YyXxIGDuGi"
      },
      "source": [
        "cv_ridge.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLoTo8qzI7Bj"
      },
      "source": [
        "model_ridge = Ridge(alpha=1)\n",
        "model_ridge.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHVPgUqPUIzZ"
      },
      "source": [
        "data1 = data\n",
        "data1.drop(overfit,axis=1,inplace=True)\n",
        "data1.drop(('nutriscore_score'), axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJquTgVcLsod"
      },
      "source": [
        "coef = pd.Series(model_ridge.coef_.ravel(), index = data1.columns)\n",
        "print(\"Ridge picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXspUwpYMGLG"
      },
      "source": [
        "model_ridge.coef_.ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhXRi1_YURtd"
      },
      "source": [
        "rid_coef = pd.concat([coef.sort_values().head(10),coef.sort_values().tail(10)])\n",
        "rid_coef"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC97K1_sTnhT"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
        "rid_coef.plot(kind = \"barh\")\n",
        "plt.title(\"Coefficients in the Ridge Model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDpUtrzzUljC"
      },
      "source": [
        "#let's look at the residuals as well:\n",
        "plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
        "\n",
        "preds = pd.DataFrame({\"preds\":model_ridge.predict(X_train).ravel(), \"true\":y_train.ravel()})\n",
        "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
        "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr1-yNL1N3a2"
      },
      "source": [
        "The Lasso Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld2UcrNwEoqS"
      },
      "source": [
        "model_lasso = LassoCV(alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50]).fit(X_train, y_train.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPb6JYLFE-2B"
      },
      "source": [
        "rmse_cv(model_lasso).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTtMcYQOGYDm"
      },
      "source": [
        "coef = pd.Series(model_lasso.coef_, index = data1.columns)\n",
        "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZnnJD7gHyPh"
      },
      "source": [
        "imp_coef = pd.concat([coef.sort_values().head(10),coef.sort_values().tail(10)])\n",
        "imp_coef"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INd0uz8HH5Ds"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
        "imp_coef.plot(kind = \"barh\")\n",
        "plt.title(\"Coefficients in the Lasso Model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUkoOnElICIf"
      },
      "source": [
        "#let's look at the residuals as well:\n",
        "plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
        "\n",
        "preds = pd.DataFrame({\"preds\":model_lasso.predict(X_train), \"true\":y_train.ravel()})\n",
        "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
        "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjMdjw3TXxft"
      },
      "source": [
        "We note that the **Ridge** method iw way better than the **lasso** method**\n",
        "\n",
        "I will know apply some Regression models an choose the model with the lowest value of the **RMSE**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsqHQvgGXwKU"
      },
      "source": [
        "train_accuracies = {'Linear Regression':[0,0],  'Support Vector Regression' : [0,0] , 'Random Forest Regression':[0,0],\n",
        "                    'Deision Tree Regression':[0,0] , 'XGBoost Regression':[0,0] , 'lightgbm Regressor' :[0,0] }\n",
        "test_accuracies = {'Linear Regression':[0,0],  'Support Vector Regression' : [0,0] , 'Random Forest Regression':[0,0],\n",
        "                    'Deision Tree Regression':[0,0] , 'XGBoost Regression':[0,0] , 'lightgbm Regressor' :[0,0] }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN9VxzY0dRB1"
      },
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X_train , y_train)\n",
        "train_preds = lr.predict(X_train)\n",
        "test_preds = lr.predict(X_test)\n",
        "scores1 = cross_val_score(lr, train_preds, y_train, scoring= 'neg_mean_squared_error', cv=5)\n",
        "scores2 = cross_val_score(lr, test_preds, y_test, scoring= 'neg_mean_squared_error', cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MawYbncFoyJ"
      },
      "source": [
        "print(\"Linear Regression results :\")\n",
        "\n",
        "print(\"   -   The Mean Squared Error on the train set : {:.7f}\".format(np.sqrt(-scores1.mean())))\n",
        "train_accuracies['Linear Regression'][0] = np.sqrt(-scores1.mean())\n",
        "print(\"   -   The Mean Squared Error Deviation on the train set : {:.7f}\".format(np.sqrt(scores1.std())))\n",
        "train_accuracies['Linear Regression'][1] = np.sqrt(scores1.std())\n",
        "\n",
        "print(\"   -   The Mean Squared Error on the test set : {:.2f}\".format(np.sqrt(-scores2.mean())))\n",
        "test_accuracies['Linear Regression'][0] = np.sqrt(-scores2.mean())\n",
        "print(\"   -   The Mean Squared Error Deviation on the test set : {:.7f}\".format(np.sqrt(scores2.std())))\n",
        "test_accuracies['Linear Regression'][1] = np.sqrt(scores2.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxIIjXzdamXK"
      },
      "source": [
        "sv = SVR(kernel = 'rbf')\n",
        "sv.fit(X_train, y_train)\n",
        "train_preds = sv.predict(X_train)\n",
        "test_preds = sv.predict(X_test)\n",
        "scores1 = cross_val_score(sv, X = train_preds.reshape(-1, 1), y = y_train.ravel(), scoring= 'neg_mean_squared_error', cv=5)\n",
        "scores2 = cross_val_score(sv, X =  test_preds.reshape(-1, 1), y = y_test.ravel(), scoring= 'neg_mean_squared_error', cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0d3zTbEZR7m"
      },
      "source": [
        "print(\"Support Vector Regression results :\")\n",
        "\n",
        "print(\"   -   The Mean Squared Error on the train set : {:.7f}\".format(np.sqrt(-scores1.mean())))\n",
        "train_accuracies['Support Vector Regression'][0] = np.sqrt(-scores1.mean())\n",
        "print(\"   -   The Mean Squared Error Deviation on the train set : {:.7f}\".format(np.sqrt(scores1.std())))\n",
        "train_accuracies['Support Vector Regression'][1] = np.sqrt(scores1.std())\n",
        "\n",
        "print(\"   -   The Mean Squared Error on the test set : {:.2f}\".format(np.sqrt(-scores2.mean())))\n",
        "test_accuracies['Support Vector Regression'][0] = np.sqrt(-scores2.mean())\n",
        "print(\"   -   The Mean Squared Error Deviation on the test set : {:.7f}\".format(np.sqrt(scores2.std())))\n",
        "test_accuracies['Support Vector Regression'][1] = np.sqrt(scores2.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iiZEmKaZSAu"
      },
      "source": [
        "dt = DecisionTreeRegressor()\n",
        "dt.fit(X_train , y_train)\n",
        "train_preds = dt.predict(X_train)\n",
        "test_preds = dt.predict(X_test)\n",
        "scores1 = cross_val_score(dt, X = train_preds.reshape(-1, 1), y = y_train.ravel(), scoring= 'neg_mean_squared_error', cv=10)\n",
        "scores2 = cross_val_score(dt, X =  test_preds.reshape(-1, 1), y = y_test.ravel(), scoring= 'neg_mean_squared_error', cv=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdzLCDkzZR_c"
      },
      "source": [
        "print(\"Deision Tree Regression results :\")\n",
        "\n",
        "print(\"   -   The Mean Squared Error on the train set : {:.7f}\".format(np.sqrt(-scores1.mean())))\n",
        "train_accuracies['Deision Tree Regression'][0] = np.sqrt(-scores1.mean())\n",
        "print(\"   -   The Mean Squared Error Deviation on the train set : {:.7f}\".format(np.sqrt(scores1.std())))\n",
        "train_accuracies['Deision Tree Regression'][1] = np.sqrt(scores1.std())\n",
        "\n",
        "print(\"   -   The Mean Squared Error on the test set : {:.2f}\".format(np.sqrt(-scores2.mean())))\n",
        "test_accuracies['Deision Tree Regression'][0] = np.sqrt(-scores2.mean())\n",
        "print(\"   -   The Mean Squared Error Deviation on the test set : {:.7f}\".format(np.sqrt(scores2.std())))\n",
        "test_accuracies['Deision Tree Regression'][1] = np.sqrt(scores2.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "817aorppZR6F"
      },
      "source": [
        "rf = RandomForestRegressor()\n",
        "rf.fit(X_train , y_train)\n",
        "train_preds = rf.predict(X_train)\n",
        "test_preds = rf.predict(X_test)\n",
        "scores1 = cross_val_score(rf, X = train_preds.reshape(-1, 1), y = y_train.ravel(), scoring= 'neg_mean_squared_error', cv=10)\n",
        "scores2 = cross_val_score(rf, X =  test_preds.reshape(-1, 1), y = y_test.ravel(), scoring= 'neg_mean_squared_error', cv=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_kIyOpWgq6Q"
      },
      "source": [
        "\n",
        "print(\"Random Forest Regression results :\")\n",
        "\n",
        "print(\"   -   The Mean Squared Error on the train set : {:.7f}\".format(np.sqrt(-scores1.mean())))\n",
        "train_accuracies['Random Forest Regression'][0] = np.sqrt(-scores1.mean())\n",
        "print(\"   -   The Mean Squared Error Deviation on the train set : {:.7f}\".format(np.sqrt(scores1.std())))\n",
        "train_accuracies['Random Forest Regression'][1] = np.sqrt(scores1.std())\n",
        "\n",
        "print(\"   -   The Mean Squared Error on the test set : {:.2f}\".format(np.sqrt(-scores2.mean())))\n",
        "test_accuracies['Random Forest Regression'][0] = np.sqrt(-scores2.mean())\n",
        "print(\"   -   The Mean Squared Error Deviation on the test set : {:.7f}\".format(np.sqrt(scores2.std())))\n",
        "test_accuracies['Random Forest Regression'][1] = np.sqrt(scores2.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEJ-CU9lgq4s"
      },
      "source": [
        "gb = XGBRegressor()\n",
        "gb.fit(X_train , y_train)\n",
        "train_preds = gb.predict(X_train)\n",
        "test_preds = gb.predict(X_test)\n",
        "scores1 = cross_val_score(gb, X = train_preds.reshape(-1, 1), y = y_train.ravel(), scoring= 'neg_mean_squared_error', cv=10)\n",
        "scores2 = cross_val_score(gb, X =  test_preds.reshape(-1, 1), y = y_test.ravel(), scoring= 'neg_mean_squared_error', cv=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1vBoNEVgq2H"
      },
      "source": [
        "rint(\"XGBoost Regression results :\")\n",
        "\n",
        "print(\"   -   The Mean Squared Error on the train set : {:.7f}\".format(np.sqrt(-scores1.mean())))\n",
        "train_accuracies['XGBoost Regression'][0] = np.sqrt(-scores1.mean())\n",
        "print(\"   -   The Mean Squared Error Deviation on the train set : {:.7f}\".format(np.sqrt(scores1.std())))\n",
        "train_accuracies['XGBoost Regression'][1] = np.sqrt(scores1.std())\n",
        "\n",
        "print(\"   -   The Mean Squared Error on the test set : {:.2f}\".format(np.sqrt(-scores2.mean())))\n",
        "test_accuracies['XGBoost Regression'][0] = np.sqrt(-scores2.mean())\n",
        "print(\"   -   The Mean Squared Error Deviation on the test set : {:.7f}\".format(np.sqrt(scores2.std())))\n",
        "test_accuracies['XGBoost Regression'][1] = np.sqrt(scores2.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZxwEZmWgq0O"
      },
      "source": [
        "gbm = lgb.LGBMRegressor()\n",
        "gbm.fit(X_train , y_train)\n",
        "train_preds = gbm.predict(X_train)\n",
        "test_preds = gbm.predict(X_test)\n",
        "scores1 = cross_val_score(gbm, X = train_preds.reshape(-1, 1), y = y_train.ravel(), scoring= 'neg_mean_squared_error', cv=10)\n",
        "scores2 = cross_val_score(gbm, X =  test_preds.reshape(-1, 1), y = y_test.ravel(), scoring= 'neg_mean_squared_error', cv=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrtvPIr_hPAz"
      },
      "source": [
        "print(\"lightgbm Regressor results :\")\n",
        "\n",
        "print(\"   -   The Mean Squared Error on the train set : {:.7f}\".format(np.sqrt(-scores1.mean())))\n",
        "train_accuracies['lightgbm Regressor'][0] = np.sqrt(-scores1.mean())\n",
        "print(\"   -   The Mean Squared Error Deviation on the train set : {:.7f}\".format(np.sqrt(scores1.std())))\n",
        "train_accuracies['lightgbm Regressor'][1] = np.sqrt(scores1.std())\n",
        "\n",
        "print(\"   -   The Mean Squared Error on the test set : {:.2f}\".format(np.sqrt(-scores2.mean())))\n",
        "test_accuracies['lightgbm Regressor'][0] = np.sqrt(-scores2.mean())\n",
        "print(\"   -   The Mean Squared Error Deviation on the test set : {:.7f}\".format(np.sqrt(scores2.std())))\n",
        "test_accuracies['lightgbm Regressor'][1] = np.sqrt(scores2.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td3kzCdjhPEm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyqrtXi9hO_A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}